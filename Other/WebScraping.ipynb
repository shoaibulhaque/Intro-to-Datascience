{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Web Scraping**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ul>\n",
    "        <li>\n",
    "            <a href=\"https://bso/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01\">Beautiful Soup Object</a>\n",
    "            <ul>\n",
    "                <li>Tag</li>\n",
    "                <li>Children, Parents, and Siblings</li>\n",
    "                <li>HTML Attributes</li>\n",
    "                <li>Navigable String</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "     </ul>\n",
    "    <ul>\n",
    "        <li>\n",
    "            <a href=\"https://filter/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01\">Filter</a>\n",
    "            <ul>\n",
    "                <li>find All</li>\n",
    "                <li>find </li>\n",
    "                <li>HTML Attributes</li>\n",
    "                <li>Navigable String</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "     </ul>\n",
    "     <ul>\n",
    "        <li>\n",
    "            <a href=\"https://dscw/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01\">Downloading And Scraping The Contents Of A Web</a>\n",
    "    </li>\n",
    "         </ul>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we are going to be using Python and several Python libraries. Some of these libraries might be installed in your environment. Others may need to be installed by you. The cells below will install these libraries when executed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (0.15.3) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['bs4==4.10.0']\n",
      "\n",
      "pkgs/r/noarch            [<=>                 ] (00m:00s) \n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 712 KB / ?? (2.31 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 712 KB / ?? (2.31 MB/s)\n",
      "pkgs/main/linux-64       [<=>                 ] (00m:00s) \n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 712 KB / ?? (2.31 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 712 KB / ?? (2.31 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) \n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 712 KB / ?? (2.31 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 748 KB / ?? (2.39 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 712 KB / ?? (2.31 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 748 KB / ?? (2.39 MB/s)\n",
      "pkgs/r/linux-64          [<=>                 ] (00m:00s) \n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 712 KB / ?? (2.31 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 748 KB / ?? (2.39 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 728 KB / ?? (2.33 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 712 KB / ?? (2.31 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) Finalizing...\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 728 KB / ?? (2.33 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 712 KB / ?? (2.31 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) Done\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 728 KB / ?? (2.33 MB/s)\n",
      "pkgs/main/noarch         [====================] (00m:00s) Done\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 712 KB / ?? (2.31 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 728 KB / ?? (2.33 MB/s)\n",
      "pkgs/r/noarch            [<=>                 ] (00m:00s) Finalizing...\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 728 KB / ?? (2.33 MB/s)\n",
      "pkgs/r/noarch            [<=>                 ] (00m:00s) Done\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 728 KB / ?? (2.33 MB/s)\n",
      "pkgs/r/noarch            [====================] (00m:00s) Done\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 728 KB / ?? (2.33 MB/s)\n",
      "pkgs/main/linux-64       [<=>               ] (00m:00s) 648 KB / ?? (2.08 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 728 KB / ?? (2.33 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.56 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 728 KB / ?? (2.33 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.56 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 728 KB / ?? (2.33 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.56 MB/s)\n",
      "pkgs/r/linux-64          [ <=>                ] (00m:00s) 1 MB / ?? (2.87 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.56 MB/s)\n",
      "pkgs/r/linux-64          [ <=>                ] (00m:00s) Finalizing...\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.56 MB/s)\n",
      "pkgs/r/linux-64          [ <=>                ] (00m:00s) Done\n",
      "pkgs/r/linux-64          [====================] (00m:00s) Done\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.56 MB/s)\n",
      "pkgs/main/linux-64       [  <=>               ] (00m:00s) 1 MB / ?? (2.56 MB/s)\n",
      "pkgs/main/linux-64       [  <=>               ] (00m:00s) 2 MB / ?? (3.34 MB/s)\n",
      "pkgs/main/linux-64       [   <=>              ] (00m:00s) 2 MB / ?? (3.34 MB/s)\n",
      "pkgs/main/linux-64       [   <=>              ] (00m:00s) 3 MB / ?? (3.65 MB/s)\n",
      "pkgs/main/linux-64       [    <=>             ] (00m:00s) 3 MB / ?? (3.65 MB/s)\n",
      "pkgs/main/linux-64       [    <=>             ] (00m:00s) 4 MB / ?? (3.85 MB/s)\n",
      "pkgs/main/linux-64       [     <=>            ] (00m:00s) 4 MB / ?? (3.85 MB/s)\n",
      "pkgs/main/linux-64       [     <=>            ] (00m:00s) 4 MB / ?? (4.00 MB/s)\n",
      "pkgs/main/linux-64       [      <=>           ] (00m:00s) 4 MB / ?? (4.00 MB/s)\n",
      "pkgs/main/linux-64       [      <=>           ] (00m:00s) 5 MB / ?? (4.11 MB/s)\n",
      "pkgs/main/linux-64       [      <=>           ] (00m:01s) Finalizing...\n",
      "pkgs/main/linux-64       [      <=>           ] (00m:01s) Done\n",
      "pkgs/main/linux-64       [====================] (00m:01s) Done\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - bs4==4.10.0\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package               Version  Build           Channel                  Size\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[32m  + bs4            \u001b[00m      4.10.0  hd3eb1b0_0      pkgs/main/noarch        10 KB\n",
      "\n",
      "  Upgrade:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - ca-certificates\u001b[00m   2022.9.24  ha878542_0      installed                    \n",
      "\u001b[32m  + ca-certificates\u001b[00m  2023.01.10  h06a4308_0      pkgs/main/linux-64     120 KB\n",
      "\u001b[31m  - certifi        \u001b[00m   2022.9.24  pyhd8ed1ab_0    installed                    \n",
      "\u001b[32m  + certifi        \u001b[00m   2022.12.7  py37h06a4308_0  pkgs/main/linux-64     150 KB\n",
      "\u001b[31m  - openssl        \u001b[00m      1.1.1s  h0b41bf4_1      installed                    \n",
      "\u001b[32m  + openssl        \u001b[00m      1.1.1t  h7f8727e_0      pkgs/main/linux-64       4 MB\n",
      "\n",
      "  Downgrade:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - beautifulsoup4 \u001b[00m      4.11.1  pyha770c72_0    installed                    \n",
      "\u001b[32m  + beautifulsoup4 \u001b[00m      4.10.0  pyh06a4308_0    pkgs/main/noarch        85 KB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 1 packages\n",
      "  Upgrade: 3 packages\n",
      "  Downgrade: 1 packages\n",
      "\n",
      "  Total download: 4 MB\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Downloading  [>                                        ] (00m:00s)   58.18 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished bs4                                  (00m:00s)              10 KB     58 KB/s\n",
      "Downloading  [>                                        ] (00m:00s)   58.18 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)   58.18 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)   58.18 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)  543.29 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished beautifulsoup4                       (00m:00s)              85 KB    484 KB/s\n",
      "Downloading  [>                                        ] (00m:00s)  543.29 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)  543.29 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [==>                                      ] (00m:00s)    1.16 MB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished ca-certificates                      (00m:00s)             120 KB    666 KB/s\n",
      "Downloading  [==>                                      ] (00m:00s)    1.16 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [==>                                      ] (00m:00s)    1.16 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [==>                                      ] (00m:00s)    1.16 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [==>                                      ] (00m:00s)    1.16 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    1.95 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "\u001b[2A\u001b[0KFinished certifi                              (00m:00s)             150 KB    826 KB/s\n",
      "Downloading  [===>                                     ] (00m:00s)    1.95 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    1.95 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [=========================================] (00m:00s)   18.52 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [=========================================] (00m:00s)   18.52 MB/s\n",
      "Extracting   [================>                        ] (00m:00s)        2 / 5\n",
      "Downloading  [=========================================] (00m:00s)   18.52 MB/s\n",
      "Extracting   [================>                        ] (00m:00s)        2 / 5\n",
      "Downloading  [=========================================] (00m:00s)   18.52 MB/s\n",
      "Extracting   [========================>                ] (00m:00s)        3 / 5\n",
      "Downloading  [=========================================] (00m:00s)   18.52 MB/s\n",
      "Extracting   [========================>                ] (00m:00s)        3 / 5\n",
      "\u001b[2A\u001b[0KFinished openssl                              (00m:00s)               4 MB     18 MB/s\n",
      "Downloading  [=========================================] (00m:00s)   18.52 MB/s\n",
      "Extracting   [========================>                ] (00m:00s)        3 / 5\n",
      "Downloading  [=========================================] (00m:00s)   18.52 MB/s\n",
      "Extracting   [========================>                ] (00m:00s)        3 / 5\n",
      "Downloading  [=========================================] (00m:00s)   18.52 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "Downloading  [=========================================] (00m:00s)   18.52 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "Downloading  [=========================================] (00m:00s)   18.52 MB/s\n",
      "Extracting   [=========================================] (00m:00s)        5 / 5\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting lxml==4.6.4\n",
      "  Downloading lxml-4.6.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.9.1\n",
      "    Uninstalling lxml-4.9.1:\n",
      "      Successfully uninstalled lxml-4.9.1\n",
      "Successfully installed lxml-4.6.4\n",
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (0.15.3) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['html5lib==1.1']\n",
      "\n",
      "pkgs/main/linux-64       Using cache\n",
      "pkgs/main/noarch         Using cache\n",
      "pkgs/r/linux-64          Using cache\n",
      "pkgs/r/noarch            Using cache\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - html5lib==1.1\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package         Version  Build         Channel                 Size\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[32m  + html5lib    \u001b[00m      1.1  pyhd3eb1b0_0  pkgs/main/noarch       91 KB\n",
      "\u001b[32m  + webencodings\u001b[00m    0.5.1  py37_1        pkgs/main/linux-64     19 KB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 2 packages\n",
      "\n",
      "  Total download: 110 KB\n",
      "\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Downloading  [>                                        ] (00m:00s)    3.45 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)    3.45 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=================================>       ] (00m:00s)  593.61 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished html5lib                             (00m:00s)              91 KB    591 KB/s\n",
      "Downloading  [=================================>       ] (00m:00s)  593.61 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=================================>       ] (00m:00s)  593.61 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=================================>       ] (00m:00s)  593.61 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=========================================] (00m:00s)  646.57 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished webencodings                         (00m:00s)              19 KB    112 KB/s\n",
      "Downloading  [=========================================] (00m:00s)  646.57 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=========================================] (00m:00s)  646.57 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=========================================] (00m:00s)  646.57 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  646.57 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  646.57 KB/s\n",
      "Extracting   [=========================================] (00m:00s)        2 / 2\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting requests==2.26.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests==2.26.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests==2.26.0) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests==2.26.0) (3.4)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Installing collected packages: charset-normalizer, requests\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.1.1\n",
      "    Uninstalling charset-normalizer-2.1.1:\n",
      "      Successfully uninstalled charset-normalizer-2.1.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ibm-cos-sdk-core 2.12.0 requires requests<3.0,>=2.27.1, but you have requests 2.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed charset-normalizer-2.0.12 requests-2.26.0\n"
     ]
    }
   ],
   "source": [
    "!mamba install bs4==4.10.0 -y\n",
    "!pip install lxml==4.6.4\n",
    "!mamba install html5lib==1.1 -y\n",
    "!pip install requests==2.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import html5lib\n",
    "import requests  # this module helps us to download a web page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"BSO\">Beautiful Soup Objects</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files, we will focus on HTML files. This is accomplished by representing the HTML as a set of objects with methods used to parse the HTML.  We can navigate the HTML as a tree and/or filter out what we are looking for.\n",
    "\n",
    "Consider the following HTML:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>Page Title</title>\n",
       "</head>\n",
       "<body>\n",
       "<h3><b id='boldest'>Lebron James</b></h3>\n",
       "<p> Salary: $ 92,000,000 </p>\n",
       "<h3> Stephen Curry</h3>\n",
       "<p> Salary: $85,000, 000 </p>\n",
       "<h3> Kevin Durant </h3>\n",
       "<p> Salary: $73,200, 000</p>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<title>Page Title</title>\n",
    "</head>\n",
    "<body>\n",
    "<h3><b id='boldest'>Lebron James</b></h3>\n",
    "<p> Salary: $ 92,000,000 </p>\n",
    "<h3> Stephen Curry</h3>\n",
    "<p> Salary: $85,000, 000 </p>\n",
    "<h3> Kevin Durant </h3>\n",
    "<p> Salary: $73,200, 000</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store it as a string in the variable HTML:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=\"<!DOCTYPE html><html><head><title>Page Title</title></head><body><h3><b id='boldest'>Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body></html>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse a document, pass it into the <code>BeautifulSoup</code> constructor, the <code>BeautifulSoup</code> object, which represents the document as a nested data structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html><head><title>Page Title</title></head><body><h3><b id=\"boldest\">Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body></html>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the document is converted to Unicode, (similar to ASCII),  and HTML entities are converted to Unicode characters. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. The <code>BeautifulSoup</code> object can create other types of objects. In this , we will cover <code>BeautifulSoup</code> and <code>Tag</code> objects that for the purposes of this are identical, and <code>NavigableString</code> objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the method <code>prettify()</code> to display the HTML in the nested structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Page Title\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h3>\n",
      "   <b id=\"boldest\">\n",
      "    Lebron James\n",
      "   </b>\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $ 92,000,000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Stephen Curry\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $85,000, 000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Kevin Durant\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $73,200, 000\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want the  title of the page and the name of the top paid player we can use the <code>Tag</code>. The <code>Tag</code> object corresponds to an HTML tag in the original document, for example, the tag title.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag object: <title>Page Title</title>\n"
     ]
    }
   ],
   "source": [
    "tag_object = soup.title\n",
    "print(\"tag object:\", tag_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see the tag type <code>bs4.element.Tag</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag object type: <class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "print(\"tag object type:\", type(tag_object))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is more than one <code>Tag</code>  with the same name, the first element with that <code>Tag</code> name is called, this corresponds to the most paid player:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Lebron James</b></h3>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_object = soup.h3\n",
    "tag_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enclosed in the bold attribute <code>b</code>, it helps to use the tree representation. We can navigate down the tree using the child attribute to get the name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Children, Parents, and Siblings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above the <code>Tag</code> object is a tree of objects we can access the child of the tag or navigate down the branch as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b id=\"boldest\">Lebron James</b>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child = tag_object.b\n",
    "tag_child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the parent with the <code> parent</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Lebron James</b></h3>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_tag = tag_child.parent\n",
    "parent_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is identical to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Lebron James</b></h3>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>tag_object</code> parent is the <code>body</code> element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body><h3><b id=\"boldest\">Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_object.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>tag_object</code> sibling is the <code>paragraph</code> element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p> Salary: $ 92,000,000 </p>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_1 = tag_object.next_sibling\n",
    "sibling_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sibling_2` is the `header` element which is also a sibling of both `sibling_1` and `tag_object`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3> Stephen Curry</h3>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_2 = sibling_1.next_sibling\n",
    "sibling_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"first_question\">Exercise: <code>next_sibling</code></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the object <code>sibling\\_2</code> and the property <code>next_sibling</code> to find the salary of Stephen Curry:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p> Salary: $85,000, 000 </p>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sibling_3 = sibling_2.next_sibling\n",
    "sibling_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "sibling_2.next_sibling\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the tag has attributes, the tag <code>id=\"boldest\"</code> has an attribute <code>id</code> whose value is <code>boldest</code>. You can access a tag’s attributes by treating the tag like a dictionary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boldest'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access that dictionary directly as <code>attrs</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'boldest'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also work with Multi-valued attribute check out <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01\">\\[1]</a> for more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also obtain the content if the attribute of the <code>tag</code> using the Python <code>get()</code> method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boldest'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_child.get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigable String\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A string corresponds to a bit of text or content within a tag. Beautiful Soup uses the <code>NavigableString</code> class to contain this text. In our HTML we can obtain the name of the first player by extracting the sting of the <code>Tag</code> object <code>tag_child</code> as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lebron James'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_string = tag_child.string\n",
    "tag_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can verify the type is Navigable String\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.NavigableString"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tag_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A NavigableString is just like a Python string or Unicode string, to be more precise. The main difference is that it also supports some  <code>BeautifulSoup</code> features. We can covert it to sting object in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lebron James'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicode_string = str(tag_string)\n",
    "unicode_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"filter\">Filter</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters allow you to find complex patterns, the simplest filter is a string. In this section we will pass a string to a different filter method and Beautiful Soup will perform a match against that exact string.  Consider the following HTML of rocket launchs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <td id='flight' >Flight No</td>\n",
       "    <td>Launch site</td> \n",
       "    <td>Payload mass</td>\n",
       "   </tr>\n",
       "  <tr> \n",
       "    <td>1</td>\n",
       "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
       "    <td>300 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>2</td>\n",
       "    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n",
       "    <td>94 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>3</td>\n",
       "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n",
       "    <td>80 kg</td>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<table>\n",
    "  <tr>\n",
    "    <td id='flight' >Flight No</td>\n",
    "    <td>Launch site</td> \n",
    "    <td>Payload mass</td>\n",
    "   </tr>\n",
    "  <tr> \n",
    "    <td>1</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n",
    "    <td>300 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n",
    "    <td>94 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n",
    "    <td>80 kg</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store it as a string in the variable <code>table</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=\"<table><tr><td id='flight'>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a></td><td>300 kg</td></tr><tr><td>2</td><td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td><td>80 kg</td></tr></table>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr></table>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs = BeautifulSoup(table, \"html.parser\")\n",
    "table_bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find All\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>find_all()</code> method looks through a tag’s descendants and retrieves all descendants that match your filters.\n",
    "\n",
    "<p>\n",
    "The Method signature for <code>find_all(name, attrs, recursive, string, limit, **kwargs)<c/ode>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we set the <code>name</code> parameter to a tag name, the method will extract all the tags with that name and its children.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n",
       " <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr>,\n",
       " <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n",
       " <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows=table_bs.find_all('tr')\n",
    "table_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a Python Iterable just like a list, each element is a <code>tag</code> object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row =table_rows[0]\n",
    "first_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type is <code>tag</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "print(type(first_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can obtain the child\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td id=\"flight\">Flight No</td>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row.td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we iterate through the list, each element corresponds to a row in the table:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: 0, is <tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>\n",
      "[<td id=\"flight\">Flight No</td>, <td>Launch site</td>, <td>Payload mass</td>]\n",
      "row: 1, is <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr>\n",
      "[<td>1</td>, <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td>, <td>300 kg</td>]\n",
      "row: 2, is <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>\n",
      "[<td>2</td>, <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>, <td>94 kg</td>]\n",
      "row: 3, is <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr>\n",
      "[<td>3</td>, <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td>, <td>80 kg</td>]\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(table_rows):\n",
    "    print(f\"row: {i}, is {row}\")\n",
    "    # cells = row.find_all('td')\n",
    "    # print(cells)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As <code>row</code> is a <code>cell</code> object, we can apply the method <code>find_all</code> to it and extract table cells in the object <code>cells</code> using the tag <code>td</code>, this is all the children with the name <code>td</code>. The result is a list, each element corresponds to a cell and is a <code>Tag</code> object, we can iterate through this list as well. We can extract the content using the <code>string</code>  attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0\n",
      "column 0 cell: <td id=\"flight\">Flight No</td>\n",
      "column 1 cell: <td>Launch site</td>\n",
      "column 2 cell: <td>Payload mass</td>\n",
      "row 1\n",
      "column 0 cell: <td>1</td>\n",
      "column 1 cell: <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td>\n",
      "column 2 cell: <td>300 kg</td>\n",
      "row 2\n",
      "column 0 cell: <td>2</td>\n",
      "column 1 cell: <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\n",
      "column 2 cell: <td>94 kg</td>\n",
      "row 3\n",
      "column 0 cell: <td>3</td>\n",
      "column 1 cell: <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td>\n",
      "column 2 cell: <td>80 kg</td>\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(table_rows):\n",
    "    print(f\"row {i}\")\n",
    "    cells = row.find_all('td')\n",
    "    for j, cell in enumerate(cells):\n",
    "        print(f\"column {j} cell: {cell}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use a list we can match against any item in that list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n",
       " <td id=\"flight\">Flight No</td>,\n",
       " <td>Launch site</td>,\n",
       " <td>Payload mass</td>,\n",
       " <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr>,\n",
       " <td>1</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td>,\n",
       " <td>300 kg</td>,\n",
       " <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n",
       " <td>2</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n",
       " <td>94 kg</td>,\n",
       " <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr>,\n",
       " <td>3</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td>,\n",
       " <td>80 kg</td>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input=table_bs .find_all(name=[\"tr\", \"td\"])\n",
    "list_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the argument is not recognized it will be turned into a filter on the tag’s attributes. For example the <code>id</code>  argument, Beautiful Soup will filter against each tag’s <code>id</code> attribute. For example, the first <code>td</code> elements have a value of <code>id</code> of <code>flight</code>, therefore we can filter based on that <code>id</code> value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td id=\"flight\">Flight No</td>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(id=\"flight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find all the elements that have links to the Florida Wikipedia page:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input=table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Florida\")\n",
    "list_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set the  <code>href</code> attribute to True, regardless of what the value is, the code finds all tags with <code>href</code> value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(href=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other methods for dealing with attributes and other related methods; Check out the following <a href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork23455606-2021-01-01#css-selectors'>link</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"exer_type\">Exercise: <code>find_all</code></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the logic above, find all the elements without <code>href</code> value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<table><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr></table>,\n",
       " <tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n",
       " <td id=\"flight\">Flight No</td>,\n",
       " <td>Launch site</td>,\n",
       " <td>Payload mass</td>,\n",
       " <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td><td>300 kg</td></tr>,\n",
       " <td>1</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a></a></a></td>,\n",
       " <a></a>,\n",
       " <td>300 kg</td>,\n",
       " <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n",
       " <td>2</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n",
       " <td>94 kg</td>,\n",
       " <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td><td>80 kg</td></tr>,\n",
       " <td>3</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida<a> </a></a></td>,\n",
       " <a> </a>,\n",
       " <td>80 kg</td>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(href = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "table_bs.find_all(href=False)\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the soup object <code>soup</code>, find the element with the <code>id</code> attribute content set to <code>\"boldest\"</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<html><head><title>Page Title</title></head><body><h3><b id=\"boldest\">Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body></html>,\n",
       " <head><title>Page Title</title></head>,\n",
       " <title>Page Title</title>,\n",
       " <body><h3><b id=\"boldest\">Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body>,\n",
       " <h3><b id=\"boldest\">Lebron James</b></h3>,\n",
       " <b id=\"boldest\">Lebron James</b>,\n",
       " <p> Salary: $ 92,000,000 </p>,\n",
       " <h3> Stephen Curry</h3>,\n",
       " <p> Salary: $85,000, 000 </p>,\n",
       " <h3> Kevin Durant </h3>,\n",
       " <p> Salary: $73,200, 000</p>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id == 'boldest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "soup.find_all(id=\"boldest\")\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With string you can search for strings instead of tags, where we find all the elments with Florida:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Florida', 'Florida']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(string=\"Florida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>find_all()</code> method scans the entire document looking for results, it’s if you are looking for one element you can use the <code>find()</code> method to find the first element in the document. Consider the following two table:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Rocket Launch </h3>\n",
       "\n",
       "<p>\n",
       "<table class='rocket'>\n",
       "  <tr>\n",
       "    <td>Flight No</td>\n",
       "    <td>Launch site</td> \n",
       "    <td>Payload mass</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>1</td>\n",
       "    <td>Florida</td>\n",
       "    <td>300 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>2</td>\n",
       "    <td>Texas</td>\n",
       "    <td>94 kg</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>3</td>\n",
       "    <td>Florida </td>\n",
       "    <td>80 kg</td>\n",
       "  </tr>\n",
       "</table>\n",
       "</p>\n",
       "<p>\n",
       "\n",
       "<h3>Pizza Party  </h3>\n",
       "  \n",
       "    \n",
       "<table class='pizza'>\n",
       "  <tr>\n",
       "    <td>Pizza Place</td>\n",
       "    <td>Orders</td> \n",
       "    <td>Slices </td>\n",
       "   </tr>\n",
       "  <tr>\n",
       "    <td>Domino's Pizza</td>\n",
       "    <td>10</td>\n",
       "    <td>100</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Little Caesars</td>\n",
       "    <td>12</td>\n",
       "    <td >144 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Papa John's </td>\n",
       "    <td>15 </td>\n",
       "    <td>165</td>\n",
       "  </tr>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<h3>Rocket Launch </h3>\n",
    "\n",
    "<p>\n",
    "<table class='rocket'>\n",
    "  <tr>\n",
    "    <td>Flight No</td>\n",
    "    <td>Launch site</td> \n",
    "    <td>Payload mass</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Florida</td>\n",
    "    <td>300 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>Texas</td>\n",
    "    <td>94 kg</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>Florida </td>\n",
    "    <td>80 kg</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</p>\n",
    "<p>\n",
    "\n",
    "<h3>Pizza Party  </h3>\n",
    "  \n",
    "    \n",
    "<table class='pizza'>\n",
    "  <tr>\n",
    "    <td>Pizza Place</td>\n",
    "    <td>Orders</td> \n",
    "    <td>Slices </td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <td>Domino's Pizza</td>\n",
    "    <td>10</td>\n",
    "    <td>100</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Little Caesars</td>\n",
    "    <td>12</td>\n",
    "    <td >144 </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Papa John's </td>\n",
    "    <td>15 </td>\n",
    "    <td>165</td>\n",
    "  </tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the HTML as a Python string and assign <code>two_tables</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_tables=\"<h3>Rocket Launch </h3><p><table class='rocket'><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table></p><p><h3>Pizza Party  </h3><table class='pizza'><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td >144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a <code>BeautifulSoup</code> object  <code>two_tables_bs</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_tables_bs= BeautifulSoup(two_tables, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the first table using the tag name table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"rocket\"><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_tables_bs.find(\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter on the class attribute to find the second table, but because class is a keyword in Python, we add an underscore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"pizza\"><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td>144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr></table>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_tables_bs.find(\"table\",class_='pizza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"DSCW\">Downloading And Scraping The Contents Of A Web Page</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Download the contents of the web page:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.ibm.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use <code>get</code> to download the contents of the webpage in text format and store in a variable called <code>data</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = requests.get(url).text  # getting body as text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a <code>BeautifulSoup</code> object using the <code>BeautifulSoup</code> constructor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,\"html.parser\")  # create a soup object using the variable 'data'\n",
    "# soup.find_all('a', href = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape all links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ibm.com/products/turbonomic\n",
      "https://www.ibm.com/products/api-connect\n",
      "https://www.ibm.com/resources/automation-innovation-workshop\n",
      "https://www.ibm.com/automation\n",
      "https://www.ibm.com/downloads/cas/RZQKRMKO\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "https://www.ibm.com/employment/?lnk=flatitem\n",
      "https://www.ibm.com/impact\n",
      "https://research.ibm.com/\n",
      "https://www.ibm.com/consulting/?lnk=flathl\n",
      "https://www.ibm.com/consulting/strategy/?lnk=flathl\n",
      "https://www.ibm.com/consulting/ibmix?lnk=flathl\n",
      "https://www.ibm.com/consulting/technology/\n",
      "https://www.ibm.com/consulting/operations/?lnk=flathl\n",
      "https://www.ibm.com/strategic-partnerships\n",
      "https://www.ibm.com/products/instana\n",
      "https://www.ibm.com/products/turbonomic\n",
      "https://www.ibm.com/automation\n",
      "https://www.ibm.com/products/envizi\n",
      "https://www.ibm.com/products/maximo\n",
      "https://www.ibm.com/sustainability\n",
      "https://www.ibm.com/cloud/campaign/cloud-simplicity\n",
      "https://www.ibm.com/cloud/campaign/cloud-simplicity\n",
      "http://ibm.com/consulting/ibmix\n",
      "https://www.ibm.com/consulting\n",
      "https://www.ibm.com/sports/masters\n",
      "https://www.ibm.com/cloud/watson-knowledge-catalog\n",
      "https://www.ibm.com/data-management\n",
      "https://www.ibm.com/data-fabric\n",
      "https://www.ibm.com/\n"
     ]
    }
   ],
   "source": [
    "# scrapping all the links\n",
    "for link in soup.find_all('a', href= True):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape  all images  Tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"Flat illustration for Threat Intelligence Index representing an attack surface threat and response\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0b526ddf40c413f5/security-leadspace-desktop.jpg.global.mr_5x4.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0b526ddf40c413f5/security-leadspace-desktop.jpg.global.mr_5x4.jpg\n",
      "<img alt=\"Workers in a tap room\" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/p/0b52088cc24c2f3d/CS-The-Automate-Beer-Question-30_ProRes_frame-13-22.png.global.sr_5x4.png\"/>\n",
      "https://1.dam.s81c.com/p/0b52088cc24c2f3d/CS-The-Automate-Beer-Question-30_ProRes_frame-13-22.png.global.sr_5x4.png\n",
      "<img alt=\"View of the sky between skyscrapers\" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/p/0b526ddf40c4140c/CS_The_Sustainability_Building_Question_30_ProRes-frame-07-00.png.global.sr_5x4.png\"/>\n",
      "https://1.dam.s81c.com/p/0b526ddf40c4140c/CS_The_Sustainability_Building_Question_30_ProRes-frame-07-00.png.global.sr_5x4.png\n",
      "<img alt=\"Person working in office behind computer screen\" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/p/0b52088cc24c2f41/CS_The_Modernize_Banking_Question_V1_30_ProRes_frame-00-06.png.global.sr_5x4.png\"/>\n",
      "https://1.dam.s81c.com/p/0b52088cc24c2f41/CS_The_Modernize_Banking_Question_V1_30_ProRes_frame-00-06.png.global.sr_5x4.png\n",
      "<img alt=\"Aerial view of the Masters golf course with the leader-board\" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/p/0b52088cc24c2f37/CS_the_transform_masters_question_30_prores_frame00.png.global.mr_5x4.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0b52088cc24c2f37/CS_the_transform_masters_question_30_prores_frame00.png.global.mr_5x4.jpg\n",
      "<img alt=\"Person sitting behind a desk in an office\" class=\"bx--image__img bx--card__img\" src=\"https://1.dam.s81c.com/p/0b52088cc24c2f35/CS_The_Modernize_Banking_Question_V1_30_ProRes-frame-04-30.png.global.sr_5x4.png\"/>\n",
      "https://1.dam.s81c.com/p/0b52088cc24c2f35/CS_The_Modernize_Banking_Question_V1_30_ProRes-frame-04-30.png.global.sr_5x4.png\n",
      "<img alt=\"Grid of diverse group of professionals\" aria-describedby=\"bx--image-7\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0aac9cf57bcbf324/dotcom-1-overview.jpg.global.sr_16x9.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0aac9cf57bcbf324/dotcom-1-overview.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"professional pointing to a chart\" aria-describedby=\"bx--image-8\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0aac9cf57c4bf381/0935e0d55846b9ec_dotcom-2-strategy.jpg.global.m_16x9.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0aac9cf57c4bf381/0935e0d55846b9ec_dotcom-2-strategy.jpg.global.m_16x9.jpg\n",
      "<img alt=\"two professionals working with a whiteboard outdoors\" aria-describedby=\"bx--image-9\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0aac9cf57c4bf382/0656655b47a3af8b_dotcom-3-experience.jpg.global.sr_16x9.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0aac9cf57c4bf382/0656655b47a3af8b_dotcom-3-experience.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"professionals working with a sticky notes on a whiteboard\" aria-describedby=\"bx--image-10\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0aac9cf57c4bf383/08f9513598a70746_dotcom-4-technology.jpg.global.sr_16x9.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0aac9cf57c4bf383/08f9513598a70746_dotcom-4-technology.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"professionals having a conversation in an office\" aria-describedby=\"bx--image-11\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0aac9cf57c4bf380/0935e0d55846b9e4_dotcom-5-operations.jpg.global.sr_16x9.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0aac9cf57c4bf380/0935e0d55846b9e4_dotcom-5-operations.jpg.global.sr_16x9.jpg\n",
      "<img alt=\"group of professionals walking down stairs outdoors\" aria-describedby=\"bx--image-12\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0aac9cf57c4bf384/064e0139f5a3aa3f_dotcom-6-partners.jpg.global.sr_16x9.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0aac9cf57c4bf384/064e0139f5a3aa3f_dotcom-6-partners.jpg.global.sr_16x9.jpg\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('img'):# in html image is represented by the tag <img>\n",
    "    print(link)\n",
    "    print(link.get('src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below url contains an html table with data about colors and color codes.\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to scrape a web site, you need to examine the contents, and the way data is organized on the website. Open the above url in your browser and check how many rows and columns are there in the color table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(data,\"html.parser\")\n",
    "\n",
    "soup = BeautifulSoup(data, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table border=\"1\" class=\"main-table\">\n",
       "<tr>\n",
       "<td>Number </td>\n",
       "<td>Color</td>\n",
       "<td>Color Name</td>\n",
       "<td>Hex Code<br/>#RRGGBB</td>\n",
       "<td>Decimal Code<br/>(R,G,B)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>1</td>\n",
       "<td style=\"background:lightsalmon;\"> </td>\n",
       "<td>lightsalmon</td>\n",
       "<td>#FFA07A</td>\n",
       "<td>rgb(255,160,122)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>2</td>\n",
       "<td style=\"background:salmon;\"> </td>\n",
       "<td>salmon</td>\n",
       "<td>#FA8072</td>\n",
       "<td>rgb(250,128,114)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>3</td>\n",
       "<td style=\"background:darksalmon;\"> </td>\n",
       "<td>darksalmon</td>\n",
       "<td>#E9967A</td>\n",
       "<td>rgb(233,150,122)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>4</td>\n",
       "<td style=\"background:lightcoral;\"> </td>\n",
       "<td>lightcoral</td>\n",
       "<td>#F08080</td>\n",
       "<td>rgb(240,128,128)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>5</td>\n",
       "<td style=\"background:coral;\"> </td>\n",
       "<td>coral</td>\n",
       "<td>#FF7F50</td>\n",
       "<td>rgb(255,127,80)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>6</td>\n",
       "<td style=\"background:tomato;\"> </td>\n",
       "<td>tomato</td>\n",
       "<td>#FF6347</td>\n",
       "<td>rgb(255,99,71)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>7</td>\n",
       "<td style=\"background:orangered;\"> </td>\n",
       "<td>orangered</td>\n",
       "<td>#FF4500</td>\n",
       "<td>rgb(255,69,0)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>8</td>\n",
       "<td style=\"background:gold;\"> </td>\n",
       "<td>gold</td>\n",
       "<td>#FFD700</td>\n",
       "<td>rgb(255,215,0)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>9</td>\n",
       "<td style=\"background:orange;\"> </td>\n",
       "<td>orange</td>\n",
       "<td>#FFA500</td>\n",
       "<td>rgb(255,165,0)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>10</td>\n",
       "<td style=\"background:darkorange;\"> </td>\n",
       "<td>darkorange</td>\n",
       "<td>#FF8C00</td>\n",
       "<td>rgb(255,140,0)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>11</td>\n",
       "<td style=\"background:lightyellow;\"> </td>\n",
       "<td>lightyellow</td>\n",
       "<td>#FFFFE0</td>\n",
       "<td>rgb(255,255,224)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>12</td>\n",
       "<td style=\"background:lemonchiffon;\"> </td>\n",
       "<td>lemonchiffon</td>\n",
       "<td>#FFFACD</td>\n",
       "<td>rgb(255,250,205)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>13</td>\n",
       "<td style=\"background:papayawhip;\"> </td>\n",
       "<td>papayawhip</td>\n",
       "<td>#FFEFD5</td>\n",
       "<td>rgb(255,239,213)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>14</td>\n",
       "<td style=\"background:moccasin;\"> </td>\n",
       "<td>moccasin</td>\n",
       "<td>#FFE4B5</td>\n",
       "<td>rgb(255,228,181)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>15</td>\n",
       "<td style=\"background:peachpuff;\"> </td>\n",
       "<td>peachpuff</td>\n",
       "<td>#FFDAB9</td>\n",
       "<td>rgb(255,218,185)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>16</td>\n",
       "<td style=\"background:palegoldenrod;\"> </td>\n",
       "<td>palegoldenrod</td>\n",
       "<td>#EEE8AA</td>\n",
       "<td>rgb(238,232,170)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>17</td>\n",
       "<td style=\"background:khaki;\"> </td>\n",
       "<td>khaki</td>\n",
       "<td>#F0E68C</td>\n",
       "<td>rgb(240,230,140)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>18</td>\n",
       "<td style=\"background:darkkhaki;\"> </td>\n",
       "<td>darkkhaki</td>\n",
       "<td>#BDB76B</td>\n",
       "<td>rgb(189,183,107)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>19</td>\n",
       "<td style=\"background:yellow;\"> </td>\n",
       "<td>yellow</td>\n",
       "<td>#FFFF00</td>\n",
       "<td>rgb(255,255,0)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>20</td>\n",
       "<td style=\"background:lawngreen;\"> </td>\n",
       "<td>lawngreen</td>\n",
       "<td>#7CFC00</td>\n",
       "<td>rgb(124,252,0)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>21</td>\n",
       "<td style=\"background:chartreuse;\"> </td>\n",
       "<td>chartreuse</td>\n",
       "<td>#7FFF00</td>\n",
       "<td>rgb(127,255,0)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>22</td>\n",
       "<td style=\"background:limegreen;\"> </td>\n",
       "<td>limegreen</td>\n",
       "<td>#32CD32</td>\n",
       "<td>rgb(50,205,50)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>23</td>\n",
       "<td style=\"background:lime;\"> </td>\n",
       "<td>lime</td>\n",
       "<td>#00FF00</td>\n",
       "<td>rgb(0.255.0)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>24</td>\n",
       "<td style=\"background:forestgreen;\"> </td>\n",
       "<td>forestgreen</td>\n",
       "<td>#228B22</td>\n",
       "<td>rgb(34,139,34)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>25</td>\n",
       "<td style=\"background:green;\"> </td>\n",
       "<td>green</td>\n",
       "<td>#008000</td>\n",
       "<td>rgb(0,128,0)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>26</td>\n",
       "<td style=\"background:powderblue;\"> </td>\n",
       "<td>powderblue</td>\n",
       "<td>#B0E0E6</td>\n",
       "<td>rgb(176,224,230)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>27</td>\n",
       "<td style=\"background:lightblue;\"> </td>\n",
       "<td>lightblue</td>\n",
       "<td>#ADD8E6</td>\n",
       "<td>rgb(173,216,230)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>28</td>\n",
       "<td style=\"background:lightskyblue;\"> </td>\n",
       "<td>lightskyblue</td>\n",
       "<td>#87CEFA</td>\n",
       "<td>rgb(135,206,250)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>29</td>\n",
       "<td style=\"background:skyblue;\"> </td>\n",
       "<td>skyblue</td>\n",
       "<td>#87CEEB</td>\n",
       "<td>rgb(135,206,235)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>30</td>\n",
       "<td style=\"background:deepskyblue;\"> </td>\n",
       "<td>deepskyblue</td>\n",
       "<td>#00BFFF</td>\n",
       "<td>rgb(0,191,255)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>31</td>\n",
       "<td style=\"background:lightsteelblue;\"> </td>\n",
       "<td>lightsteelblue</td>\n",
       "<td>#B0C4DE</td>\n",
       "<td>rgb(176,196,222)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>32</td>\n",
       "<td style=\"background:dodgerblue;\"> </td>\n",
       "<td>dodgerblue</td>\n",
       "<td>#1E90FF</td>\n",
       "<td>rgb(30,144,255)</td>\n",
       "</tr>\n",
       "</table>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find a html table in the web page\n",
    "table = soup.find('table') # in html table is represented by the tag <table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Name ----> None\n",
      "lightsalmon ----> #FFA07A\n",
      "salmon ----> #FA8072\n",
      "darksalmon ----> #E9967A\n",
      "lightcoral ----> #F08080\n",
      "coral ----> #FF7F50\n",
      "tomato ----> #FF6347\n",
      "orangered ----> #FF4500\n",
      "gold ----> #FFD700\n",
      "orange ----> #FFA500\n",
      "darkorange ----> #FF8C00\n",
      "lightyellow ----> #FFFFE0\n",
      "lemonchiffon ----> #FFFACD\n",
      "papayawhip ----> #FFEFD5\n",
      "moccasin ----> #FFE4B5\n",
      "peachpuff ----> #FFDAB9\n",
      "palegoldenrod ----> #EEE8AA\n",
      "khaki ----> #F0E68C\n",
      "darkkhaki ----> #BDB76B\n",
      "yellow ----> #FFFF00\n",
      "lawngreen ----> #7CFC00\n",
      "chartreuse ----> #7FFF00\n",
      "limegreen ----> #32CD32\n",
      "lime ----> #00FF00\n",
      "forestgreen ----> #228B22\n",
      "green ----> #008000\n",
      "powderblue ----> #B0E0E6\n",
      "lightblue ----> #ADD8E6\n",
      "lightskyblue ----> #87CEFA\n",
      "skyblue ----> #87CEEB\n",
      "deepskyblue ----> #00BFFF\n",
      "lightsteelblue ----> #B0C4DE\n",
      "dodgerblue ----> #1E90FF\n"
     ]
    }
   ],
   "source": [
    "#Get all rows from the table\n",
    "for row in table.find_all('tr'):\n",
    "    # get cols\n",
    "    cols = row.find_all('td')\n",
    "    col_name = cols[2].string\n",
    "    col_code = cols[3].string\n",
    "    print(\"{} ----> {}\".format(col_name, col_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables into a DataFrame using BeautifulSoup and Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd # importing pandas\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below url contains html tables with data about world population.\n",
    "url = \"https://en.wikipedia.org/wiki/World_population\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding to scrape a web site, you need to examine the contents, and the way data is organized on the website. Open the above url in your browser and check the tables on the webpage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all html tables in the web page\n",
    "tables = soup.find_all('table') # in html table is represented by the tag <table>\n",
    "# examine tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see how many tables were found by checking the length of the tables list\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we are looking for the `10 most densly populated countries` table, we can look through the tables list and find the right one we are look for based on the data in each table or we can search for the table name if it is in the table but this option might not always work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "for index,table in enumerate(tables):\n",
    "    if (\"10 most densely populated countries\" in str(table)):\n",
    "        table_index = index\n",
    "print(table_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can locate the table name of the table, `10 most densly populated countries`, below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"wikitable sortable\" style=\"text-align:right\">\n",
       "<caption>10 most densely populated countries <small>(with population above 5 million)</small><sup class=\"reference\" id=\"cite_ref-:10_107-0\"><a href=\"#cite_note-:10-107\">[102]</a></sup>\n",
       "</caption>\n",
       "<tbody><tr>\n",
       "<th scope=\"col\">Rank\n",
       "</th>\n",
       "<th scope=\"col\">Country\n",
       "</th>\n",
       "<th scope=\"col\">Population\n",
       "</th>\n",
       "<th scope=\"col\">Area<br/><small>(km<sup>2</sup>)</small>\n",
       "</th>\n",
       "<th scope=\"col\">Density<br/><small>(pop/km<sup>2</sup>)</small>\n",
       "</th></tr>\n",
       "<tr>\n",
       "<td>1</td>\n",
       "<td align=\"left\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/23px-Flag_of_Singapore.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/35px-Flag_of_Singapore.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/48/Flag_of_Singapore.svg/45px-Flag_of_Singapore.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Singapore\" title=\"Singapore\">Singapore</a></td>\n",
       "<td>5,921,231</td>\n",
       "<td>719</td>\n",
       "<td>8,235\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>2</td>\n",
       "<td align=\"left\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"1000\" decoding=\"async\" height=\"14\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/23px-Flag_of_Bangladesh.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/35px-Flag_of_Bangladesh.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Flag_of_Bangladesh.svg/46px-Flag_of_Bangladesh.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Bangladesh\" title=\"Bangladesh\">Bangladesh</a></td>\n",
       "<td>165,650,475</td>\n",
       "<td>148,460</td>\n",
       "<td>1,116\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>3</td>\n",
       "<td align=\"left\">\n",
       "<p><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"216\" data-file-width=\"432\" decoding=\"async\" height=\"12\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/00/Flag_of_Palestine.svg/23px-Flag_of_Palestine.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/00/Flag_of_Palestine.svg/35px-Flag_of_Palestine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/00/Flag_of_Palestine.svg/46px-Flag_of_Palestine.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/State_of_Palestine\" title=\"State of Palestine\">Palestine</a><sup class=\"reference\" id=\"cite_ref-108\"><a href=\"#cite_note-108\">[103]</a></sup>\n",
       "</p>\n",
       "</td>\n",
       "<td>5,223,000</td>\n",
       "<td>6,025</td>\n",
       "<td>867\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>4</td>\n",
       "<td align=\"left\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/23px-Flag_of_the_Republic_of_China.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/35px-Flag_of_the_Republic_of_China.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/72/Flag_of_the_Republic_of_China.svg/45px-Flag_of_the_Republic_of_China.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Taiwan\" title=\"Taiwan\">Taiwan</a></td>\n",
       "<td>23,580,712</td>\n",
       "<td>35,980</td>\n",
       "<td>655\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>5</td>\n",
       "<td align=\"left\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/23px-Flag_of_South_Korea.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/35px-Flag_of_South_Korea.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/09/Flag_of_South_Korea.svg/45px-Flag_of_South_Korea.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/South_Korea\" title=\"South Korea\">South Korea</a></td>\n",
       "<td>51,844,834</td>\n",
       "<td>99,720</td>\n",
       "<td>520\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>6</td>\n",
       "<td align=\"left\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/23px-Flag_of_Lebanon.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/35px-Flag_of_Lebanon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/59/Flag_of_Lebanon.svg/45px-Flag_of_Lebanon.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Lebanon\" title=\"Lebanon\">Lebanon</a></td>\n",
       "<td>5,296,814</td>\n",
       "<td>10,400</td>\n",
       "<td>509\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>7</td>\n",
       "<td align=\"left\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/23px-Flag_of_Rwanda.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/35px-Flag_of_Rwanda.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/17/Flag_of_Rwanda.svg/45px-Flag_of_Rwanda.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Rwanda\" title=\"Rwanda\">Rwanda</a></td>\n",
       "<td>13,173,730</td>\n",
       "<td>26,338</td>\n",
       "<td>500\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>8</td>\n",
       "<td align=\"left\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"1000\" decoding=\"async\" height=\"14\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/50/Flag_of_Burundi.svg/23px-Flag_of_Burundi.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/50/Flag_of_Burundi.svg/35px-Flag_of_Burundi.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/50/Flag_of_Burundi.svg/46px-Flag_of_Burundi.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Burundi\" title=\"Burundi\">Burundi</a></td>\n",
       "<td>12,696,478</td>\n",
       "<td>27,830</td>\n",
       "<td>456\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>9</td>\n",
       "<td align=\"left\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"900\" data-file-width=\"1350\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/23px-Flag_of_India.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/35px-Flag_of_India.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/41/Flag_of_India.svg/45px-Flag_of_India.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/India\" title=\"India\">India</a></td>\n",
       "<td>1,389,637,446</td>\n",
       "<td>3,287,263</td>\n",
       "<td>423\n",
       "</td></tr>\n",
       "<tr>\n",
       "<td>10</td>\n",
       "<td align=\"left\"><span class=\"flagicon\"><img alt=\"\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"15\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/20/Flag_of_the_Netherlands.svg/23px-Flag_of_the_Netherlands.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/20/Flag_of_the_Netherlands.svg/35px-Flag_of_the_Netherlands.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/20/Flag_of_the_Netherlands.svg/45px-Flag_of_the_Netherlands.svg.png 2x\" width=\"23\"/> </span><a href=\"/wiki/Netherlands\" title=\"Netherlands\">Netherlands</a></td>\n",
       "<td>17,400,824</td>\n",
       "<td>41,543</td>\n",
       "<td>419\n",
       "</td></tr></tbody></table>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[table_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area</th>\n",
       "      <th>Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5,921,231</td>\n",
       "      <td>719</td>\n",
       "      <td>8,235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>165,650,475</td>\n",
       "      <td>148,460</td>\n",
       "      <td>1,116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>State of Palestine</td>\n",
       "      <td>5,223,000</td>\n",
       "      <td>6,025</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>23,580,712</td>\n",
       "      <td>35,980</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51,844,834</td>\n",
       "      <td>99,720</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>5,296,814</td>\n",
       "      <td>10,400</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>13,173,730</td>\n",
       "      <td>26,338</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>12,696,478</td>\n",
       "      <td>27,830</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>India</td>\n",
       "      <td>1,389,637,446</td>\n",
       "      <td>3,287,263</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>17,400,824</td>\n",
       "      <td>41,543</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank             Country     Population       Area Density\n",
       "0    1           Singapore      5,921,231        719   8,235\n",
       "1    2          Bangladesh    165,650,475    148,460   1,116\n",
       "2    3  State of Palestine      5,223,000      6,025     867\n",
       "3    4              Taiwan     23,580,712     35,980     655\n",
       "4    5         South Korea     51,844,834     99,720     520\n",
       "5    6             Lebanon      5,296,814     10,400     509\n",
       "6    7              Rwanda     13,173,730     26,338     500\n",
       "7    8             Burundi     12,696,478     27,830     456\n",
       "8    9               India  1,389,637,446  3,287,263     423\n",
       "9   10         Netherlands     17,400,824     41,543     419"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe from scrape data\n",
    "population_data = pd.DataFrame(columns = [\"Rank\",\"Country\",\"Population\",\"Area\",\"Density\"]) # creating columns\n",
    "for row in tables[table_index].find_all('tr'):\n",
    "    # finding columns \n",
    "    col = row.find_all('td')\n",
    "    if col != []:\n",
    "        Rank = col[0].text\n",
    "        Country = col[1].find('a')['title']\n",
    "        Population = col[2].text\n",
    "        Area = col[3].text\n",
    "        Density = col[4].text.strip()\n",
    "        population_data = population_data.append({\"Rank\": Rank, \"Country\": Country, \"Population\": Population, \"Area\": Area, \"Density\": Density}, ignore_index = True)\n",
    "    #     if data != \"\":\n",
    "    #         Rank = data[0]\n",
    "    #         Country = data[1].string  # 0,1,2,3,4\n",
    "    #         Population = data[2]\n",
    "    #         Area = data[3]\n",
    "    #         Density = data[4]\n",
    "    # print()\n",
    "population_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables into a DataFrame using BeautifulSoup and read_html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same `url`, `data`, `soup`, and `tables` object as in the last section we can use the `read_html` function to create a DataFrame.\n",
    "\n",
    "Remember the table we need is located in `tables[table_index]`\n",
    "\n",
    "We can now use the `pandas` function `read_html` and give it the string version of the table as well as the `flavor` which is the parsing engine `bs4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "html5lib not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_69/4059676793.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bs4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         \u001b[0mdisplayed_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplayed_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m     )\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0mretained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplayed_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflavor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"bs4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html5lib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_HTML5LIB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"html5lib not found, please install it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_BS4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BeautifulSoup4 (bs4) not found, please install it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: html5lib not found, please install it"
     ]
    }
   ],
   "source": [
    "pd.read_html(str(tables[5]), flavor='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `read_html` always returns a list of DataFrames so we must pick the one we want out of the list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (1.1)\n",
      "Requirement already satisfied: webencodings in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from html5lib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area(km2)</th>\n",
       "      <th>Density(pop/km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5704000</td>\n",
       "      <td>710</td>\n",
       "      <td>8033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>171670000</td>\n",
       "      <td>143998</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Palestine</td>\n",
       "      <td>5266785</td>\n",
       "      <td>6020</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>6856000</td>\n",
       "      <td>10452</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>23604000</td>\n",
       "      <td>36193</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51781000</td>\n",
       "      <td>99538</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>12374000</td>\n",
       "      <td>26338</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>11578000</td>\n",
       "      <td>27065</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>17660000</td>\n",
       "      <td>41526</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9430000</td>\n",
       "      <td>22072</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n",
       "0     1    Singapore     5704000        710              8033\n",
       "1     2   Bangladesh   171670000     143998              1192\n",
       "2     3    Palestine     5266785       6020               847\n",
       "3     4      Lebanon     6856000      10452               656\n",
       "4     5       Taiwan    23604000      36193               652\n",
       "5     6  South Korea    51781000      99538               520\n",
       "6     7       Rwanda    12374000      26338               470\n",
       "7     8        Haiti    11578000      27065               428\n",
       "8     9  Netherlands    17660000      41526               425\n",
       "9    10       Israel     9430000      22072               427"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_data_read_html = pd.read_html(str(tables[5]), flavor='bs4')[0]\n",
    "\n",
    "population_data_read_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data from HTML tables into a DataFrame using read_html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `read_html` function to directly get DataFrames from a `url`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list = pd.read_html(url, flavor='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 25 DataFrames just like when we used `find_all` on the `soup` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can pick the DataFrame we need out of the list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area(km2)</th>\n",
       "      <th>Density(pop/km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5704000</td>\n",
       "      <td>710</td>\n",
       "      <td>8033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>171670000</td>\n",
       "      <td>143998</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Palestine</td>\n",
       "      <td>5266785</td>\n",
       "      <td>6020</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>6856000</td>\n",
       "      <td>10452</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>23604000</td>\n",
       "      <td>36193</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51781000</td>\n",
       "      <td>99538</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>12374000</td>\n",
       "      <td>26338</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>11578000</td>\n",
       "      <td>27065</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>17660000</td>\n",
       "      <td>41526</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9430000</td>\n",
       "      <td>22072</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n",
       "0     1    Singapore     5704000        710              8033\n",
       "1     2   Bangladesh   171670000     143998              1192\n",
       "2     3    Palestine     5266785       6020               847\n",
       "3     4      Lebanon     6856000      10452               656\n",
       "4     5       Taiwan    23604000      36193               652\n",
       "5     6  South Korea    51781000      99538               520\n",
       "6     7       Rwanda    12374000      26338               470\n",
       "7     8        Haiti    11578000      27065               428\n",
       "8     9  Netherlands    17660000      41526               425\n",
       "9    10       Israel     9430000      22072               427"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_list[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `match` parameter to select the specific table we want. If the table contains a string matching the text it will be read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area(km2)</th>\n",
       "      <th>Density(pop/km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5704000</td>\n",
       "      <td>710</td>\n",
       "      <td>8033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>171670000</td>\n",
       "      <td>143998</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Palestine</td>\n",
       "      <td>5266785</td>\n",
       "      <td>6020</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>6856000</td>\n",
       "      <td>10452</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>23604000</td>\n",
       "      <td>36193</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>51781000</td>\n",
       "      <td>99538</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>12374000</td>\n",
       "      <td>26338</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>11578000</td>\n",
       "      <td>27065</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>17660000</td>\n",
       "      <td>41526</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Israel</td>\n",
       "      <td>9430000</td>\n",
       "      <td>22072</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n",
       "0     1    Singapore     5704000        710              8033\n",
       "1     2   Bangladesh   171670000     143998              1192\n",
       "2     3    Palestine     5266785       6020               847\n",
       "3     4      Lebanon     6856000      10452               656\n",
       "4     5       Taiwan    23604000      36193               652\n",
       "5     6  South Korea    51781000      99538               520\n",
       "6     7       Rwanda    12374000      26338               470\n",
       "7     8        Haiti    11578000      27065               428\n",
       "8     9  Netherlands    17660000      41526               425\n",
       "9    10       Israel     9430000      22072               427"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_html(url, match=\"10 most densely populated countries\", flavor='bs4')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
